{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up graphlab create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v1.10.1) is available! Your current version is v1.9.\n",
      "\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://dato.com/products/create/upgrade.\n"
     ]
    }
   ],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Linear regression:</pre>"
      ],
      "text/plain": [
       "Linear regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 21613</pre>"
      ],
      "text/plain": [
       "Number of examples          : 21613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of features          : 17</pre>"
      ],
      "text/plain": [
       "Number of features          : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 17</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 18</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Accelerated Gradient (FISTA)</pre>"
      ],
      "text/plain": [
       "Starting Accelerated Gradient (FISTA)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Tuning step size. First iteration could take longer than subsequent iterations.</pre>"
      ],
      "text/plain": [
       "Tuning step size. First iteration could take longer than subsequent iterations."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 0.000002  | 1.146801     | 6962915.603493     | 426631.749026 |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 0.000002  | 1.146801     | 6962915.603493     | 426631.749026 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 0.000002  | 1.176580     | 6843144.200219     | 392488.929838 |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 0.000002  | 1.176580     | 6843144.200219     | 392488.929838 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 0.000002  | 1.193685     | 6831900.032123     | 385340.166783 |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 0.000002  | 1.193685     | 6831900.032123     | 385340.166783 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 0.000002  | 1.212154     | 6847166.848958     | 384842.383767 |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 0.000002  | 1.212154     | 6847166.848958     | 384842.383767 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 6        | 0.000002  | 1.223060     | 6869667.895833     | 385998.458623 |</pre>"
      ],
      "text/plain": [
       "| 5         | 6        | 0.000002  | 1.223060     | 6869667.895833     | 385998.458623 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 7        | 0.000002  | 1.233054     | 6847177.773672     | 380824.455891 |</pre>"
      ],
      "text/plain": [
       "| 6         | 7        | 0.000002  | 1.233054     | 6847177.773672     | 380824.455891 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Iteration limit reached.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Iteration limit reached."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_all = graphlab.linear_regression.create(sales, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 6\n",
       "['(intercept)', 'bathrooms', 'sqft_living', 'sqft_living_sqrt', 'grade', 'sqft_above']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.coefficients[model_all.coefficients['value']>0]['name'][0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n",
    "(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0  :  6.25766285142e+14\n",
      "31.6227766017  :  6.25766285362e+14\n",
      "100.0  :  6.25766286058e+14\n",
      "316.227766017  :  6.25766288257e+14\n",
      "1000.0  :  6.25766295212e+14\n",
      "3162.27766017  :  6.25766317206e+14\n",
      "10000.0  :  6.25766386761e+14\n",
      "31622.7766017  :  6.25766606749e+14\n",
      "100000.0  :  6.25767302792e+14\n",
      "316227.766017  :  6.25769507644e+14\n",
      "1000000.0  :  6.25776517727e+14\n",
      "3162277.66017  :  6.25799062845e+14\n",
      "10000000.0  :  6.25883719085e+14\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "for l1 in np.logspace(1, 7, num=13):\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=l1, verbose = False)\n",
    "    pred = model.predict(validation)\n",
    "    res = validation['price'] - pred\n",
    "    rss = sum(res**2)\n",
    "    errors[l1] = rss\n",
    "    print l1, \" : \", rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "print min(errors, key=errors.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "1. What was the best value for the `l1_penalty`?\n",
    "2. What is the RSS on TEST data of the model with the best `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.56983602382e+14\n"
     ]
    }
   ],
   "source": [
    "model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=10.0, verbose = False)\n",
    "pred = model.predict(testing)\n",
    "res = testing['price'] - pred\n",
    "rss = sum(res**2)\n",
    "print rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "['(intercept)', 'bedrooms', 'bedrooms_square', 'bathrooms', 'sqft_living', 'sqft_living_sqrt', 'sqft_lot', 'sqft_lot_sqrt', 'floors', 'floors_square', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated']\n"
     ]
    }
   ],
   "source": [
    "print (model.coefficients['value']).nnz()\n",
    "print model.coefficients[model.coefficients['value']>0]['name'][0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(8, 10, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{100000000.0: 18, 206913808.11147901: 18, 1128837891.6846883: 15, 6158482110.6602545: 3, 1832980710.8324375: 13, 3792690190.7322536: 6, 2976351441.6313133: 10, 127427498.57031322: 18, 545559478.11685145: 17, 1438449888.2876658: 15, 263665089.87303555: 17, 162377673.91887242: 18, 885866790.41008317: 16, 10000000000.0: 1, 335981828.62837881: 17, 7847599703.5146227: 1, 695192796.17755914: 17, 4832930238.5717525: 5, 2335721469.0901213: 12, 428133239.8719396: 17}\n"
     ]
    }
   ],
   "source": [
    "nnzs = {}\n",
    "for l1_penalty in np.logspace(8, 10, num=20):\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=l1_penalty, verbose = False)\n",
    "    nnzs[l1_penalty] = model.coefficients['value'].nnz()\n",
    "print nnzs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzero` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzero` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2976351441.63  :  10\n"
     ]
    }
   ],
   "source": [
    "l1_penalty_min = 0\n",
    "for k in nnzs.keys():\n",
    "    if nnzs[k] > max_nonzeros and k > l1_penalty_min:\n",
    "        l1_penalty_min = k\n",
    "print l1_penalty_min, \" : \", nnzs[l1_penalty_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3792690190.73  :  6\n"
     ]
    }
   ],
   "source": [
    "l1_penalty_max = l1_penalty_values[-1]\n",
    "for k in nnzs.keys():\n",
    "    if nnzs[k] < max_nonzeros and k < l1_penalty_max:\n",
    "        l1_penalty_max = k\n",
    "print l1_penalty_max, \" : \", nnzs[l1_penalty_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc8840ad190>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEECAYAAADNv0QiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc8e7aa2350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xscale('log')\n",
    "plt.plot(l1_penalty_values, [nnzs[k] for k in sorted(nnzs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "\n",
    "What values did you find for `l1_penalty_min` and`l1_penalty_max`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3448968612.16 ( 11 )  :  1.04693748875e+15\n",
      "3491933809.48 ( 12 )  :  1.05114762561e+15\n",
      "3534899006.81 ( 13 )  :  1.05599273534e+15\n",
      "3577864204.13 ( 14 )  :  1.06079953176e+15\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for l1 in l1_penalty_values:\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=l1, verbose = False)\n",
    "    nnz = model.coefficients['value'].nnz()\n",
    "    if nnz == 7:\n",
    "        pred = model.predict(validation)\n",
    "        res = validation['price'] - pred\n",
    "        rss = sum(res**2)\n",
    "        print l1, \"(\", count, \")\", \" : \", rss\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`? 3448968612.16\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype: str\n",
       "Rows: 7\n",
       "['(intercept)', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_living_sqrt', 'grade', 'sqft_above']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelf = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=3448968612.16, verbose = False)\n",
    "modelf.coefficients[modelf.coefficients['value']>0]['name'][0:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
